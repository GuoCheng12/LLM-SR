"""
Find the mathematical function skeleton that represents acceleration in a damped nonlinear oscillator system with driving force, given data on time, position, and velocity.
This function form can only contain differentiable mathematial terms.
"""

import torch
import numpy as np

#Initialize parameters
MAX_NPARAMS = 10
PRAMS_INIT = [torch.nn.Parameter(torch.tensor(1.0)) for _ in range(MAX_NPARAMS)]


@evaluate.run
def evaluate(data: dict) -> float:
    """ Evaluate the equation on data observations."""
    import logging
    
    logging.info(f"SPEC: evaluate() called with data keys: {list(data.keys())}")
    logging.info(f"SPEC: data types: {[(k, type(v)) for k, v in data.items()]}")
    
    # Load data observations
    if 'inputs' in data and 'outputs' in data:
        logging.info("SPEC: Using standard inputs/outputs format")
        # Standard format: inputs/outputs (ensure torch tensors)
        inputs = torch.tensor(data['inputs'], dtype=torch.float32) if isinstance(data['inputs'], np.ndarray) else data['inputs']
        outputs = torch.tensor(data['outputs'], dtype=torch.float32) if isinstance(data['outputs'], np.ndarray) else data['outputs']
        logging.info(f"SPEC: Converted inputs shape: {inputs.shape}, outputs shape: {outputs.shape}")
        t, x, v = inputs[:,0], inputs[:,1], inputs[:,2]
    else:
        logging.info("SPEC: Using multi-group direct columns format")
        # Multi-group format: direct columns
        t = torch.tensor(data['t'], dtype=torch.float32) if isinstance(data['t'], np.ndarray) else data['t']
        x = torch.tensor(data['datax'], dtype=torch.float32) if isinstance(data['datax'], np.ndarray) else data['datax']
        v = torch.tensor(data['datav'], dtype=torch.float32) if isinstance(data['datav'], np.ndarray) else data['datav']
        outputs = torch.tensor(data['dataa'], dtype=torch.float32) if isinstance(data['dataa'], np.ndarray) else data['dataa']
        logging.info(f"SPEC: Converted t: {t.shape}, x: {x.shape}, v: {v.shape}, outputs: {outputs.shape}")
    
    # Optimize parameters based on data
    LR = 1e-4
    N_ITERATIONS = 10000
    
    logging.info(f"SPEC: Starting optimization with LR={LR}, N_ITERATIONS={N_ITERATIONS}")
    logging.info(f"SPEC: Data shapes - t: {t.shape}, x: {x.shape}, v: {v.shape}, outputs: {outputs.shape}")

    class Model(torch.nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.params = torch.nn.ParameterList(PRAMS_INIT)
        def forward(self, t, x, v):
            return equation(t, x, v, self.params)

    try:
        model = Model()
        optimizer = torch.optim.Adam(model.parameters(), lr=LR)
        logging.info(f"SPEC: Model and optimizer created successfully")

        for i in range(N_ITERATIONS):
            try:
                optimizer.zero_grad()
                logging.info(f"SPEC: Iteration {i} - calling model...")
                y_pred = model(t, x, v)
                logging.info(f"SPEC: Iteration {i} - model returned shape: {y_pred.shape}")
                
                loss = torch.mean((y_pred - outputs) ** 2)
                logging.info(f"SPEC: Iteration {i} - loss calculated: {loss.item()}")
                
                if torch.isnan(loss) or torch.isinf(loss):
                    logging.error(f"SPEC: Loss became NaN/Inf at iteration {i}: {loss}")
                    return None, None
                    
                logging.info(f"SPEC: Iteration {i} - calling backward...")
                loss.backward()
                logging.info(f"SPEC: Iteration {i} - backward completed, calling optimizer.step...")
                optimizer.step()
                logging.info(f"SPEC: Iteration {i} - optimizer.step completed")
                
                if i % 1000 == 0:
                    logging.info(f"SPEC: Iteration {i}, loss: {loss.item()}")
                    
                if i >= 5:  # Only do first few iterations with detailed logging
                    break
                    
            except Exception as e:
                logging.error(f"SPEC: Exception in iteration {i}: {e}")
                import traceback
                logging.error(f"SPEC: Traceback: {traceback.format_exc()}")
                return None, None
        
        params_values = [p.item() for p in model.params]
        final_loss = loss.item()
        logging.info(f"SPEC: Optimization completed. Final loss: {final_loss}")
        logging.info(f"SPEC: Final params: {params_values}")
        
        # Return evaluation score
        if torch.isnan(loss) or torch.isinf(loss):
            logging.error(f"SPEC: Final loss is NaN/Inf: {final_loss}")
            return None, None
        else:
            logging.info(f"SPEC: Returning score: {-final_loss}")
            return -final_loss, params_values
            
    except Exception as e:
        logging.error(f"SPEC: Exception during optimization: {e}")
        return None, None



@equation.evolve
def equation(t: torch.Tensor, x: torch.Tensor, v: torch.Tensor, params: torch.nn.ParameterList) -> torch.Tensor:
    """ Mathematical function for acceleration in a damped nonlinear oscillator

    Args:
        t (torch.Tensor): time.
        x (torch.Tensor): observations of current position.
        v (torch.Tensor): observations of velocity.
        params (torch.nn.ParameterList): List of numeric constants or parameters to be optimized

    Return:
        torch.Tensor: acceleration as the result of applying the mathematical function to the inputs.
    """
    import logging
    logging.info(f"SPEC: equation() called with shapes - t: {t.shape}, x: {x.shape}, v: {v.shape}")
    logging.info(f"SPEC: params length: {len(params)}")
    
    try:
        dv = params[0] * t  +  params[1] * x +  params[2] * v + params[3]
        logging.info(f"SPEC: equation() returning shape: {dv.shape}")
        return dv
    except Exception as e:
        logging.error(f"SPEC: Exception in equation(): {e}")
        import traceback
        logging.error(f"SPEC: Traceback: {traceback.format_exc()}")
        raise